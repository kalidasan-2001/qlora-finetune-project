name: CI

on:
  push:
  pull_request:

jobs:
  build-and-dryrun:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Upgrade pip
        run: python -m pip install --upgrade pip

      - name: Install CPU torch and deps (skip torch/bitsandbytes pins)
        shell: bash
        run: |
          set -e
          pip install --index-url https://download.pytorch.org/whl/cpu torch==2.3.0
          awk 'tolower($0) !~ /^torch/ && tolower($0) !~ /^bitsandbytes/' requirements.txt > requirements-ci.txt
          pip install -r requirements-ci.txt

      - name: Prepare minimal dataset
        shell: bash
        run: |
          mkdir -p data
          if [ ! -s data/sft.jsonl ]; then
            echo '{"messages":[{"role":"system","content":"You are a helpful, concise assistant."},{"role":"user","content":"What is LoRA?"},{"role":"assistant","content":"LoRA fine-tunes models using small low-rank adapters while freezing base weights."}]}' > data/sft.jsonl
          fi
          wc -l data/sft.jsonl

      - name: Tiny dry-run training (CPU, tiny GPT-2)
        env:
          HF_HOME: ${{ github.workspace }}/.cache/huggingface
          TOKENIZERS_PARALLELISM: "false"
          BASE_MODEL: sshleifer/tiny-gpt2
          USE_4BIT: "0"
          MAX_SEQ_LEN: "64"
          GRAD_ACCUM: "1"
          MAX_STEPS: "1"
          OUT_DIR: runs/ci-test
        run: |
          python -u scripts/train.py

      - name: Verify adapter was created
        run: |
          test -d runs/ci-test/adapter || (echo "Adapter not found" && exit 1)
          ls -la runs/ci-test/adapter